{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5 - Cobert-Faiss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1X0lRlfUkYcR3QVSTPnNXUgm2EvBg6Yx7",
      "authorship_tag": "ABX9TyOwX1nLnXSJpAUv4ycTK/X/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3d27cfce85840d5ac785a062b822bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cbbbbfa4ae22463d91e776930af29b7b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1fd193c642e64dcb916a2d92a0324b0a",
              "IPY_MODEL_e891a7c8d9e148ea8f152e62a9d1d11c"
            ]
          }
        },
        "cbbbbfa4ae22463d91e776930af29b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fd193c642e64dcb916a2d92a0324b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1eab773152f246a69be46cb0be71076c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 871891,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 871891,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f53371b5bcca465897132dc18cfc8edf"
          }
        },
        "e891a7c8d9e148ea8f152e62a9d1d11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ea5b7318fbf470eac603d7a3ea8f79f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 872k/872k [00:00&lt;00:00, 908kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1caa4d2a08154cb08a986a684eac6f73"
          }
        },
        "1eab773152f246a69be46cb0be71076c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f53371b5bcca465897132dc18cfc8edf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ea5b7318fbf470eac603d7a3ea8f79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1caa4d2a08154cb08a986a684eac6f73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f14437444d54b9e993de92c20b081b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_009117f09c434cfb9b81d69da2586a6f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a26d19a0c994c76aaae540950ef323d",
              "IPY_MODEL_28600f6d49124043bc89cc0651444701"
            ]
          }
        },
        "009117f09c434cfb9b81d69da2586a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a26d19a0c994c76aaae540950ef323d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85c5305d6ebb4482b8e929744873e141",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1715180,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1715180,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e8bb428481e4ce999eaba108a83d69a"
          }
        },
        "28600f6d49124043bc89cc0651444701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_34870651ab72441d9e23cd516ef35bb0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.72M/1.72M [00:04&lt;00:00, 425kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bee0461ba5f4db396c6699a414196a8"
          }
        },
        "85c5305d6ebb4482b8e929744873e141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e8bb428481e4ce999eaba108a83d69a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34870651ab72441d9e23cd516ef35bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bee0461ba5f4db396c6699a414196a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b454b69b3a784a87a54173c58ee713cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_192b07562e04449487699b07c5242e75",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_531445b042bb4a62b30067884208235e",
              "IPY_MODEL_a10f1fd2fa284e8a874d26fc2f4eee56"
            ]
          }
        },
        "192b07562e04449487699b07c5242e75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "531445b042bb4a62b30067884208235e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_880b3ef3944d4badbb8923feffa67e69",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67a26149bc394d5a932927cb90a6f355"
          }
        },
        "a10f1fd2fa284e8a874d26fc2f4eee56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_152d2873dc8944d9a8b4965765934fbd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:02&lt;00:00, 13.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_108d9b24110e444cac3fb501c24e5f5b"
          }
        },
        "880b3ef3944d4badbb8923feffa67e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67a26149bc394d5a932927cb90a6f355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "152d2873dc8944d9a8b4965765934fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "108d9b24110e444cac3fb501c24e5f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a988e929c716429987399eea2e3f47be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f99fbdabff3e482bbc747f97e4236587",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_949673d0658a4558a0856378810dd297",
              "IPY_MODEL_ff6a9a3f9f3a43df96e815b36c0674a9"
            ]
          }
        },
        "f99fbdabff3e482bbc747f97e4236587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "949673d0658a4558a0856378810dd297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c7fa74707e7a40d389f5f9f56af7a609",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca4fa4755e9443d592b4943333b52a15"
          }
        },
        "ff6a9a3f9f3a43df96e815b36c0674a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4dcd52926f5a426e861a237ef5c9b2ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 1.24kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7672eecd9d064bbda253db082c94a78e"
          }
        },
        "c7fa74707e7a40d389f5f9f56af7a609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca4fa4755e9443d592b4943333b52a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dcd52926f5a426e861a237ef5c9b2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7672eecd9d064bbda253db082c94a78e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adde7086f2fb44be965f6b275ca11156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3efbb8e61344410e85c89e23e580d133",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4cf9e750a53d4ea4aa0b18e8f2955b03",
              "IPY_MODEL_a7767b61a3304eb3a39ca7c9459f876e"
            ]
          }
        },
        "3efbb8e61344410e85c89e23e580d133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cf9e750a53d4ea4aa0b18e8f2955b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_415140b595634fedaae343f81410f030",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 672271273,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 672271273,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2b4b562353c413e9dc5f8f904cc8dd3"
          }
        },
        "a7767b61a3304eb3a39ca7c9459f876e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_582592e2f94a40218277844814c1284c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 672M/672M [00:35&lt;00:00, 18.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7ba86d38d7a49e9926bfd3551303a29"
          }
        },
        "415140b595634fedaae343f81410f030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2b4b562353c413e9dc5f8f904cc8dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "582592e2f94a40218277844814c1284c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7ba86d38d7a49e9926bfd3551303a29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finardi/Ranking/blob/main/5_Cobert_Faiss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knYXH0yJdrgG"
      },
      "source": [
        "%%capture\n",
        "!pip install -q ujson\n",
        "!apt install -q libomp-dev\n",
        "!pip install -q transformers\n",
        "!python -m pip -q install --upgrade faiss faiss-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJs2yTwSd6Z1"
      },
      "source": [
        "import gc\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import time\n",
        "import ujson\n",
        "import torch\n",
        "import faiss\n",
        "import random\n",
        "import pickle\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "from transformers import BertPreTrainedModel, BertModel, BertTokenizerFast\n",
        " \n",
        "# better pandas viz\n",
        "pd.set_option('display.max_columns', 100)  \n",
        "pd.set_option('display.expand_frame_repr', 100)\n",
        "pd.set_option('max_colwidth', 700)\n",
        "pd.set_option('display.max_rows', 5000)\n",
        "  \n",
        "# save/load pickles\n",
        "def pickle_file(path, data=None):\n",
        "    if data is None:\n",
        "        with open(path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    if data is not None:\n",
        "        with open(path, 'wb') as handle:\n",
        "            pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        " \n",
        "# path base\n",
        "path_base = '/content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "c3d27cfce85840d5ac785a062b822bdf",
            "cbbbbfa4ae22463d91e776930af29b7b",
            "1fd193c642e64dcb916a2d92a0324b0a",
            "e891a7c8d9e148ea8f152e62a9d1d11c",
            "1eab773152f246a69be46cb0be71076c",
            "f53371b5bcca465897132dc18cfc8edf",
            "6ea5b7318fbf470eac603d7a3ea8f79f",
            "1caa4d2a08154cb08a986a684eac6f73",
            "1f14437444d54b9e993de92c20b081b9",
            "009117f09c434cfb9b81d69da2586a6f",
            "2a26d19a0c994c76aaae540950ef323d",
            "28600f6d49124043bc89cc0651444701",
            "85c5305d6ebb4482b8e929744873e141",
            "4e8bb428481e4ce999eaba108a83d69a",
            "34870651ab72441d9e23cd516ef35bb0",
            "8bee0461ba5f4db396c6699a414196a8",
            "b454b69b3a784a87a54173c58ee713cb",
            "192b07562e04449487699b07c5242e75",
            "531445b042bb4a62b30067884208235e",
            "a10f1fd2fa284e8a874d26fc2f4eee56",
            "880b3ef3944d4badbb8923feffa67e69",
            "67a26149bc394d5a932927cb90a6f355",
            "152d2873dc8944d9a8b4965765934fbd",
            "108d9b24110e444cac3fb501c24e5f5b",
            "a988e929c716429987399eea2e3f47be",
            "f99fbdabff3e482bbc747f97e4236587",
            "949673d0658a4558a0856378810dd297",
            "ff6a9a3f9f3a43df96e815b36c0674a9",
            "c7fa74707e7a40d389f5f9f56af7a609",
            "ca4fa4755e9443d592b4943333b52a15",
            "4dcd52926f5a426e861a237ef5c9b2ab",
            "7672eecd9d064bbda253db082c94a78e",
            "adde7086f2fb44be965f6b275ca11156",
            "3efbb8e61344410e85c89e23e580d133",
            "4cf9e750a53d4ea4aa0b18e8f2955b03",
            "a7767b61a3304eb3a39ca7c9459f876e",
            "415140b595634fedaae343f81410f030",
            "e2b4b562353c413e9dc5f8f904cc8dd3",
            "582592e2f94a40218277844814c1284c",
            "d7ba86d38d7a49e9926bfd3551303a29"
          ]
        },
        "id": "4n8XH3VDd6Um",
        "outputId": "53abf4bb-032c-4db8-e65f-1fde4b4382b9"
      },
      "source": [
        "# =============\n",
        "# âœ¨ Constants\n",
        "# =============\n",
        "bsize = 16 # N\n",
        "query_maxlen = 48\n",
        "doc_maxlen = 128\n",
        "path_model = 'bert-base-multilingual-uncased'\n",
        "\n",
        "# ==================\n",
        "# âœ¨ QueryTokenizer\n",
        "# ==================\n",
        "class QueryTokenizer():\n",
        "    def __init__(self, query_maxlen, path_tokenizer):\n",
        "        self.tok = BertTokenizerFast.from_pretrained(path_tokenizer)\n",
        "        self.query_maxlen = query_maxlen\n",
        "\n",
        "        self.cls_token, self.cls_token_id = self.tok.cls_token, self.tok.cls_token_id\n",
        "        self.sep_token, self.sep_token_id = self.tok.sep_token, self.tok.sep_token_id\n",
        "        self.mask_token, self.mask_token_id = self.tok.mask_token, self.tok.mask_token_id\n",
        "\n",
        "    def tokenize(self, batch_text, add_special_tokens=False):\n",
        "        assert type(batch_text) in [list, tuple], (type(batch_text))\n",
        "\n",
        "        tokens = [self.tok.tokenize(x, add_special_tokens=False) for x in batch_text]\n",
        "\n",
        "        if not add_special_tokens:\n",
        "            return tokens\n",
        "\n",
        "        prefix, suffix = [self.cls_token], [self.sep_token]\n",
        "        tokens = [prefix + lst + suffix + [self.mask_token] * (self.query_maxlen - (len(lst)+3)) for lst in tokens]\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, batch_text, add_special_tokens=False):\n",
        "        assert type(batch_text) in [list, tuple], (type(batch_text))\n",
        "\n",
        "        ids = self.tok(batch_text, add_special_tokens=False)['input_ids']\n",
        "\n",
        "        if not add_special_tokens:\n",
        "            return ids\n",
        "\n",
        "        prefix, suffix = [self.cls_token_id], [self.sep_token_id]\n",
        "        ids = [prefix + lst + suffix + [self.mask_token_id] * (self.query_maxlen - (len(lst)+3)) for lst in ids]\n",
        "\n",
        "        return ids\n",
        "\n",
        "    def tensorize(self, batch_text, bsize=None):\n",
        "        assert type(batch_text) in [list, tuple], (type(batch_text))\n",
        "\n",
        "        obj = self.tok(batch_text, padding='max_length', truncation=True,\n",
        "                       return_tensors='pt', max_length=self.query_maxlen)\n",
        "\n",
        "        ids, mask = obj['input_ids'], obj['attention_mask']\n",
        "\n",
        "        ids[ids == 0] = self.mask_token_id\n",
        "\n",
        "        if bsize:\n",
        "            batches = _split_into_batches(ids, mask, bsize)\n",
        "            return batches\n",
        "\n",
        "        return ids, mask\n",
        "\n",
        "# ================\n",
        "# âœ¨ DocTokenizer\n",
        "# ================\n",
        "class DocTokenizer():\n",
        "    def __init__(self, doc_maxlen, path_tokenizer):\n",
        "        self.tok = BertTokenizerFast.from_pretrained(path_tokenizer)\n",
        "        self.doc_maxlen = doc_maxlen\n",
        "\n",
        "        self.cls_token, self.cls_token_id = self.tok.cls_token, self.tok.cls_token_id\n",
        "        self.sep_token, self.sep_token_id = self.tok.sep_token, self.tok.sep_token_id\n",
        "\n",
        "    def tokenize(self, batch_text, add_special_tokens=False):\n",
        "        assert type(batch_text) in [list, tuple], (type(batch_text))\n",
        "\n",
        "        tokens = [self.tok.tokenize(x, add_special_tokens=False) for x in batch_text]\n",
        "\n",
        "        if not add_special_tokens:\n",
        "            return tokens\n",
        "\n",
        "        prefix, suffix = [self.cls_token], [self.sep_token]\n",
        "        tokens = [prefix + lst + suffix for lst in tokens]\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def encode(self, batch_text, add_special_tokens=False):\n",
        "        assert type(batch_text) in [list, tuple], (type(batch_text))\n",
        "\n",
        "        ids = self.tok(batch_text, add_special_tokens=False)['input_ids']\n",
        "\n",
        "        if not add_special_tokens:\n",
        "            return ids\n",
        "\n",
        "        prefix, suffix = [self.cls_token_id], [self.sep_token_id]\n",
        "        ids = [prefix + lst + suffix for lst in ids]\n",
        "\n",
        "        return ids\n",
        "\n",
        "    def tensorize(self, batch_text, bsize=None):\n",
        "        assert type(batch_text) in [list, tuple], (type(batch_text))\n",
        "\n",
        "        obj = self.tok(batch_text, padding='longest', truncation='longest_first',\n",
        "                       return_tensors='pt', max_length=self.doc_maxlen)\n",
        "\n",
        "        ids, mask = obj['input_ids'], obj['attention_mask']\n",
        "\n",
        "        if bsize:\n",
        "            ids, mask, reverse_indices = _sort_by_length(ids, mask, bsize)\n",
        "            batches = _split_into_batches(ids, mask, bsize)\n",
        "            return batches, reverse_indices\n",
        "\n",
        "        return ids, mask\n",
        "\n",
        "# =====================\n",
        "# âœ¨ tensorize triples\n",
        "# =====================\n",
        "def tensorize_triples(query_tokenizer, doc_tokenizer, queries, positives, negatives, bsize):\n",
        "    assert len(queries) == len(positives) == len(negatives)\n",
        "    assert bsize is None or len(queries) % bsize == 0\n",
        "\n",
        "    N = len(queries)\n",
        "    assert bsize == N\n",
        "    Q_ids, Q_mask = query_tokenizer.tensorize(queries)\n",
        "    D_ids, D_mask = doc_tokenizer.tensorize(positives + negatives)\n",
        "    D_ids, D_mask = D_ids.view(2, N, -1), D_mask.view(2, N, -1)\n",
        "\n",
        "    # Compute max among {length of i^th positive, length of i^th negative} for i \\in N\n",
        "    maxlens = D_mask.sum(-1).max(0).values\n",
        "\n",
        "    # Sort by maxlens\n",
        "    indices = maxlens.sort().indices\n",
        "    Q_ids, Q_mask = Q_ids[indices], Q_mask[indices]\n",
        "    D_ids, D_mask = D_ids[:, indices], D_mask[:, indices]\n",
        "\n",
        "    (positive_ids, negative_ids), (positive_mask, negative_mask) = D_ids, D_mask\n",
        "\n",
        "    query_batches = _split_into_batches(Q_ids, Q_mask, bsize)\n",
        "    positive_batches = _split_into_batches(positive_ids, positive_mask, bsize)\n",
        "    negative_batches = _split_into_batches(negative_ids, negative_mask, bsize)\n",
        "\n",
        "    batches = []\n",
        "    for (q_ids, q_mask), (p_ids, p_mask), (n_ids, n_mask) in zip(query_batches, positive_batches, negative_batches):\n",
        "        Q = (torch.cat((q_ids, q_ids)), torch.cat((q_mask, q_mask)))\n",
        "        D = (torch.cat((p_ids, n_ids)), torch.cat((p_mask, n_mask)))\n",
        "        batches.append((Q, D))\n",
        "\n",
        "    return batches\n",
        "\n",
        "# =============\n",
        "# âœ¨ Aux funcs\n",
        "# =============\n",
        "def _sort_by_length(ids, mask, bsize):\n",
        "    if ids.size(0) <= bsize:\n",
        "        return ids, mask, torch.arange(ids.size(0))\n",
        "\n",
        "    indices = mask.sum(-1).sort().indices\n",
        "    reverse_indices = indices.sort().indices\n",
        "\n",
        "    return ids[indices], mask[indices], reverse_indices\n",
        "\n",
        "def _split_into_batches(ids, mask, bsize):\n",
        "    batches = []\n",
        "    for offset in range(0, ids.size(0), bsize):\n",
        "        batches.append((ids[offset:offset+bsize], mask[offset:offset+bsize]))\n",
        "\n",
        "    return batches\n",
        "\n",
        "# ===============\n",
        "# âœ¨ LazyBatcher\n",
        "# ===============\n",
        "class LazyBatcher():\n",
        "    def __init__(self, bsize, path, path_tokenizer, query_maxlen, doc_maxlen, mode='train', accumsteps=1):\n",
        "        self.bsize, self.accumsteps = bsize, accumsteps\n",
        "        self.query_tokenizer = QueryTokenizer(query_maxlen=query_maxlen, path_tokenizer=path_tokenizer)\n",
        "        self.doc_tokenizer = DocTokenizer(doc_maxlen=doc_maxlen, path_tokenizer=path_tokenizer)\n",
        "        self.tensorize_triples = partial(tensorize_triples, self.query_tokenizer, self.doc_tokenizer)\n",
        "        self.position = 0\n",
        "        self.mode = mode\n",
        "\n",
        "        self.triples = self._load_triples(path_base)\n",
        "        self.queries = self._load_queries(path_base)\n",
        "        self.collection = self._load_collection(path_base)\n",
        "    \n",
        "    def _load_triples(self, path):\n",
        "        if self.mode == 'train':\n",
        "            path = path+'data/df_FAQ_triplet_IDS_TRAIN.parquet.gzip'\n",
        "        elif self.mode == 'valid':\n",
        "            path = path+'data/df_FAQ_triplet_IDS_VALID.parquet.gzip'\n",
        "\n",
        "        df_triplet = pd.read_parquet(path)\n",
        "        triples = []\n",
        "        for qid, pos_pid, neg_pid in zip(\n",
        "            df_triplet.qid.values,\n",
        "            df_triplet.pos_pid.values,\n",
        "            df_triplet.neg_pid.values\n",
        "            ):\n",
        "            triples.append((qid, pos_pid, neg_pid))\n",
        "\n",
        "        return triples\n",
        "\n",
        "    def _load_queries(self, path):\n",
        "        if self.mode == 'train':\n",
        "            qid_to_query_train = path+'data/qid_to_query_TRAIN'\n",
        "            return pickle_file(qid_to_query_train)\n",
        "        elif self.mode == 'valid':\n",
        "            qid_to_query_valid = path+'data/qid_to_query_VALID'\n",
        "            return pickle_file(qid_to_query_valid)\n",
        "\n",
        "    def _load_collection(self, path):\n",
        "        if self.mode == 'train':\n",
        "            pid_to_doc_train = path+'data/pid_to_doc_TRAIN'\n",
        "            return pickle_file(pid_to_doc_train)\n",
        "        elif self.mode == 'valid':\n",
        "            pid_to_doc_valid = path+'data/pid_to_doc_VALID'\n",
        "            return pickle_file(pid_to_doc_valid)\n",
        "        \n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.triples)\n",
        "\n",
        "    def __next__(self):\n",
        "        # offsets determines the starting index position of each bag (sequence) in input.\n",
        "        offset, endpos = self.position, min(self.position + self.bsize, len(self.triples))\n",
        "        self.position = endpos\n",
        "\n",
        "        if offset + self.bsize > len(self.triples):\n",
        "            raise StopIteration\n",
        "\n",
        "        queries, positives, negatives = [], [], []\n",
        "\n",
        "        for position in range(offset, endpos):\n",
        "            query, pos, neg = self.triples[position]\n",
        "            query, pos, neg = self.queries[query], self.collection[pos], self.collection[neg]\n",
        "            queries.append(query)\n",
        "            positives.append(pos)\n",
        "            negatives.append(neg)\n",
        "\n",
        "        return self.collate(queries, positives, negatives)\n",
        "\n",
        "    def collate(self, queries, positives, negatives):\n",
        "        assert len(queries) == len(positives) == len(negatives) == self.bsize\n",
        "\n",
        "        return self.tensorize_triples(queries, positives, negatives, self.bsize // self.accumsteps)\n",
        "\n",
        "# ===========\n",
        "# âœ¨ ColBERT\n",
        "# ===========\n",
        "class ColBERT(BertPreTrainedModel):\n",
        "    def __init__(self, config, query_maxlen, doc_maxlen, mask_punctuation, dim=128, similarity_metric='cosine'):\n",
        "\n",
        "        super(ColBERT, self).__init__(config)\n",
        "\n",
        "        self.query_maxlen = query_maxlen\n",
        "        self.doc_maxlen = doc_maxlen\n",
        "        self.similarity_metric = similarity_metric\n",
        "        self.dim = dim\n",
        "\n",
        "        self.mask_punctuation = mask_punctuation\n",
        "        self.skiplist = {}\n",
        "\n",
        "        if self.mask_punctuation:\n",
        "            self.tokenizer = BertTokenizerFast.from_pretrained(path_model)\n",
        "            self.skiplist = {w: True\n",
        "                             for symbol in string.punctuation\n",
        "                             for w in [symbol, self.tokenizer.encode(symbol, add_special_tokens=False)[0]]}\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.linear = torch.nn.Linear(config.hidden_size, dim, bias=False)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, Q, D):\n",
        "        return self.score(self.query(*Q), self.doc(*D))\n",
        "\n",
        "    def query(self, input_ids, attention_mask):\n",
        "        input_ids, attention_mask = input_ids.to(DEVICE), attention_mask.to(DEVICE)\n",
        "        Q = self.bert(input_ids, attention_mask=attention_mask)[0]\n",
        "        Q = self.linear(Q)\n",
        "\n",
        "        return torch.nn.functional.normalize(Q, p=2, dim=2)\n",
        "\n",
        "    def doc(self, input_ids, attention_mask, keep_dims=True):\n",
        "        input_ids, attention_mask = input_ids.to(DEVICE), attention_mask.to(DEVICE)\n",
        "        D = self.bert(input_ids, attention_mask=attention_mask)[0]\n",
        "        D = self.linear(D)\n",
        "\n",
        "        mask = torch.tensor(self.mask(input_ids), device=DEVICE).unsqueeze(2).float()\n",
        "        D = D * mask\n",
        "\n",
        "        D = torch.nn.functional.normalize(D, p=2, dim=2)\n",
        "\n",
        "        if not keep_dims:\n",
        "            D, mask = D.cpu().to(dtype=torch.float16), mask.cpu().bool().squeeze(-1)\n",
        "            D = [d[mask[idx]] for idx, d in enumerate(D)]\n",
        "\n",
        "        return D\n",
        "\n",
        "    def score(self, Q, D):\n",
        "        if self.similarity_metric == 'cosine':\n",
        "            return (Q @ D.permute(0, 2, 1)).max(2).values.sum(1)\n",
        "\n",
        "        assert self.similarity_metric == 'l2'\n",
        "        return (-1.0 * ((Q.unsqueeze(2) - D.unsqueeze(1))**2).sum(-1)).max(-1).values.sum(-1)\n",
        "\n",
        "    def mask(self, input_ids):\n",
        "        mask = [[(x not in self.skiplist) and (x != 0) for x in d] for d in input_ids.cpu().tolist()]\n",
        "        return mask\n",
        "\n",
        "# ==================\n",
        "# âœ¨ ModelInference\n",
        "# ==================\n",
        "class ModelInference():\n",
        "    def __init__(self, colbert, path_model):\n",
        "        assert colbert.training is False\n",
        "\n",
        "        self.colbert = colbert\n",
        "        self.query_tokenizer = QueryTokenizer(colbert.query_maxlen, path_tokenizer=path_model)\n",
        "        self.doc_tokenizer = DocTokenizer(colbert.doc_maxlen, path_tokenizer=path_model)\n",
        "\n",
        "    def query(self, *args, to_cpu=False, **kw_args):\n",
        "        with torch.no_grad():\n",
        "            Q = self.colbert.query(*args, **kw_args)\n",
        "            return Q.cpu() if to_cpu else Q\n",
        "\n",
        "    def doc(self, *args, to_cpu=False, **kw_args):\n",
        "        with torch.no_grad():\n",
        "            D = self.colbert.doc(*args, **kw_args)\n",
        "            return D.cpu() if to_cpu else D\n",
        "\n",
        "    def queryFromText(self, queries, bsize=None, to_cpu=False):\n",
        "        if bsize:\n",
        "            batches = self.query_tokenizer.tensorize(queries, bsize=bsize)\n",
        "            batches = [self.query(input_ids, attention_mask, to_cpu=to_cpu) for input_ids, attention_mask in batches]\n",
        "            return torch.cat(batches)\n",
        "\n",
        "        input_ids, attention_mask = self.query_tokenizer.tensorize(queries)\n",
        "        return self.query(input_ids, attention_mask)\n",
        "\n",
        "    def docFromText(self, docs, bsize=None, keep_dims=True, to_cpu=False):\n",
        "        if bsize:\n",
        "            batches, reverse_indices = self.doc_tokenizer.tensorize(docs, bsize=bsize)\n",
        "\n",
        "            batches = [self.doc(input_ids, attention_mask, keep_dims=keep_dims, to_cpu=to_cpu)\n",
        "                       for input_ids, attention_mask in batches]\n",
        "\n",
        "            if keep_dims:\n",
        "                D = _stack_3D_tensors(batches)\n",
        "                return D[reverse_indices]\n",
        "\n",
        "            D = [d for batch in batches for d in batch]\n",
        "            return [D[idx] for idx in reverse_indices.tolist()]\n",
        "\n",
        "        input_ids, attention_mask = self.doc_tokenizer.tensorize(docs)\n",
        "        return self.doc(input_ids, attention_mask, keep_dims=keep_dims)\n",
        "\n",
        "    def score(self, Q, D, mask=None, lengths=None, explain=False):\n",
        "        if lengths is not None:\n",
        "            assert mask is None, \"don't supply both mask and lengths\"\n",
        "\n",
        "            mask = torch.arange(D.size(1), device=DEVICE) + 1\n",
        "            mask = mask.unsqueeze(0) <= lengths.to(DEVICE).unsqueeze(-1)\n",
        "\n",
        "        scores = (D @ Q)\n",
        "        scores = scores if mask is None else scores * mask.unsqueeze(-1)\n",
        "        scores = scores.max(1)\n",
        "\n",
        "        if explain:\n",
        "            assert False, \"TODO\"\n",
        "\n",
        "        return scores.values.sum(-1).cpu()\n",
        "\n",
        "def _stack_3D_tensors(groups):\n",
        "    bsize = sum([x.size(0) for x in groups])\n",
        "    maxlen = max([x.size(1) for x in groups])\n",
        "    hdim = groups[0].size(2)\n",
        "\n",
        "    output = torch.zeros(bsize, maxlen, hdim, device=groups[0].device, dtype=groups[0].dtype)\n",
        "\n",
        "    offset = 0\n",
        "    for x in groups:\n",
        "        endpos = offset + x.size(0)\n",
        "        output[offset:endpos, :x.size(1)] = x\n",
        "        offset = endpos\n",
        "\n",
        "    return output    \n",
        "\n",
        "# - - - - -\n",
        "dataloader_train = LazyBatcher(\n",
        "    bsize=bsize, \n",
        "    path=path_base, \n",
        "    path_tokenizer=path_model,\n",
        "    query_maxlen=query_maxlen,\n",
        "    doc_maxlen=doc_maxlen,\n",
        "    mode='train'\n",
        "    )\n",
        "\n",
        "print('batches:')\n",
        "for i, batches in enumerate(dataloader_train):\n",
        "    print(f' {i }.', end ='')\n",
        "\n",
        "try:\n",
        "    del colbert\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "print()\n",
        "\n",
        "colbert = ColBERT.from_pretrained(\n",
        "    path_model,\n",
        "    query_maxlen=query_maxlen,\n",
        "    doc_maxlen=doc_maxlen,\n",
        "    dim=128,\n",
        "    similarity_metric='cosine',\n",
        "    mask_punctuation=False).to(DEVICE)        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3d27cfce85840d5ac785a062b822bdf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=871891.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f14437444d54b9e993de92c20b081b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1715180.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b454b69b3a784a87a54173c58ee713cb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "batches:\n",
            " 0. 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a988e929c716429987399eea2e3f47be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adde7086f2fb44be965f6b275ca11156",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=672271273.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing ColBERT: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ColBERT were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['linear.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHQggT0seC8O",
        "outputId": "d2b76836-c8ad-45a8-b160-bb1c42efaa09"
      },
      "source": [
        "# âœ¨ load colbert from checkpoint\n",
        "colbert.load_state_dict(torch.load(path_base+'data/EPOCH_3_FAQ'))\n",
        "print('\\nmodel loaded!\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "model loaded!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2Z1t8LCFmxf"
      },
      "source": [
        "# Faiss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Zgoqn3FpxY"
      },
      "source": [
        "# =================\n",
        "# âœ¨ FaissIndexGPU\n",
        "# =================\n",
        "class FaissIndexGPU():\n",
        "    def __init__(self):\n",
        "        self.ngpu = faiss.get_num_gpus()\n",
        "\n",
        "        if self.ngpu == 0:\n",
        "            return\n",
        "\n",
        "        self.tempmem = 1 << 33\n",
        "        self.max_add_per_gpu = 1 << 25\n",
        "        self.max_add = self.max_add_per_gpu * self.ngpu\n",
        "        self.add_batch_size = 65536\n",
        "\n",
        "        self.gpu_resources = self._prepare_gpu_resources()\n",
        "\n",
        "    def _prepare_gpu_resources(self):\n",
        "        print(f\"\\nPreparing resources for {self.ngpu} GPUs.\")\n",
        "\n",
        "        gpu_resources = []\n",
        "\n",
        "        for _ in range(self.ngpu):\n",
        "            res = faiss.StandardGpuResources()\n",
        "            if self.tempmem >= 0:\n",
        "                res.setTempMemory(self.tempmem)\n",
        "            gpu_resources.append(res)\n",
        "\n",
        "        return gpu_resources\n",
        "\n",
        "    def _make_vres_vdev(self):\n",
        "        assert self.ngpu > 0\n",
        "\n",
        "        vres = faiss.GpuResourcesVector()\n",
        "        vdev = faiss.Int32Vector()\n",
        "\n",
        "        for i in range(self.ngpu):\n",
        "            vdev.push_back(i)\n",
        "            vres.push_back(self.gpu_resources[i])\n",
        "\n",
        "        return vres, vdev\n",
        "\n",
        "    def training_initialize(self, index, quantizer):\n",
        "        assert self.ngpu > 0\n",
        "\n",
        "        s = time.time()\n",
        "        self.index_ivf = faiss.extract_index_ivf(index)\n",
        "        self.clustering_index = faiss.index_cpu_to_all_gpus(quantizer)\n",
        "        self.index_ivf.clustering_index = self.clustering_index\n",
        "\n",
        "    def training_finalize(self):\n",
        "        assert self.ngpu > 0\n",
        "\n",
        "        s = time.time()\n",
        "        self.index_ivf.clustering_index = faiss.index_gpu_to_cpu(self.index_ivf.clustering_index)\n",
        "\n",
        "    def adding_initialize(self, index):\n",
        "        assert self.ngpu > 0\n",
        "\n",
        "        self.co = faiss.GpuMultipleClonerOptions()\n",
        "        self.co.useFloat16 = True\n",
        "        self.co.useFloat16CoarseQuantizer = False\n",
        "        self.co.usePrecomputed = False\n",
        "        self.co.indicesOptions = faiss.INDICES_CPU\n",
        "        self.co.verbose = True\n",
        "        self.co.reserveVecs = self.max_add\n",
        "        self.co.shard = True\n",
        "        assert self.co.shard_type in (0, 1, 2)\n",
        "\n",
        "        self.vres, self.vdev = self._make_vres_vdev()\n",
        "        self.gpu_index = faiss.index_cpu_to_gpu_multiple(self.vres, self.vdev, index, self.co)\n",
        "\n",
        "    def add(self, index, data, offset):\n",
        "        assert self.ngpu > 0\n",
        "\n",
        "        t0 = time.time()\n",
        "        nb = data.shape[0]\n",
        "\n",
        "        for i0 in range(0, nb, self.add_batch_size):\n",
        "            i1 = min(i0 + self.add_batch_size, nb)\n",
        "            xs = data[i0:i1]\n",
        "\n",
        "            self.gpu_index.add_with_ids(xs, np.arange(offset+i0, offset+i1))\n",
        "\n",
        "            if self.max_add > 0 and self.gpu_index.ntotal > self.max_add:\n",
        "                self._flush_to_cpu(index, nb, offset)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        if self.gpu_index.ntotal > 0:\n",
        "            self._flush_to_cpu(index, nb, offset)\n",
        "\n",
        "        assert index.ntotal == offset+nb, (index.ntotal, offset+nb, offset, nb)\n",
        "\n",
        "    def _flush_to_cpu(self, index, nb, offset):\n",
        "        for i in range(self.ngpu):\n",
        "            index_src_gpu = faiss.downcast_index(self.gpu_index if self.ngpu == 1 else self.gpu_index.at(i))\n",
        "            index_src = faiss.index_gpu_to_cpu(index_src_gpu)\n",
        "\n",
        "            index_src.copy_subset_to(index, 0, offset, offset+nb)\n",
        "            index_src_gpu.reset()\n",
        "            index_src_gpu.reserveMemory(self.max_add)\n",
        "\n",
        "        if self.ngpu > 1:\n",
        "            try:\n",
        "                self.gpu_index.sync_with_shard_indexes()\n",
        "            except:\n",
        "                self.gpu_index.syncWithSubIndexes()\n",
        "\n",
        "# ==============\n",
        "# âœ¨ FaissIndex\n",
        "# ==============\n",
        "class FaissIndex():\n",
        "    def __init__(self, dim, partitions):\n",
        "        self.dim = dim\n",
        "        self.partitions = partitions\n",
        "\n",
        "        self.gpu = FaissIndexGPU()\n",
        "        self.quantizer, self.index = self._create_index()\n",
        "        self.offset = 0\n",
        "\n",
        "    def _create_index(self):\n",
        "        quantizer = faiss.IndexFlatL2(self.dim)  # faiss.IndexHNSWFlat(dim, 32)\n",
        "        index = faiss.IndexIVFPQ(quantizer, self.dim, self.partitions, 16, 8)\n",
        "\n",
        "        return quantizer, index\n",
        "\n",
        "    def train(self, train_data):\n",
        "        if self.gpu.ngpu > 0:\n",
        "            self.gpu.training_initialize(self.index, self.quantizer)\n",
        "\n",
        "        s = time.time()\n",
        "        self.index.train(train_data)\n",
        "\n",
        "        if self.gpu.ngpu > 0:\n",
        "            self.gpu.training_finalize()\n",
        "\n",
        "    def add(self, data):\n",
        "        print(f\"\\tAdd data with shape {data.shape} (offset = {self.offset})\\n\")\n",
        "\n",
        "        if self.gpu.ngpu > 0 and self.offset == 0:\n",
        "            self.gpu.adding_initialize(self.index)\n",
        "\n",
        "        if self.gpu.ngpu > 0:\n",
        "            self.gpu.add(self.index, data, self.offset)\n",
        "        else:\n",
        "            self.index.add(data)\n",
        "\n",
        "        self.offset += data.shape[0]\n",
        "\n",
        "    def save(self, output_path):\n",
        "        print(f\"\\nWriting index to {output_path}\")\n",
        "\n",
        "        self.index.nprobe = 10  # just a default\n",
        "        faiss.write_index(self.index, output_path)                \n",
        "\n",
        "# ===========\n",
        "# âœ¨ Aux fcs\n",
        "# ===========\n",
        "def load_sample(samples_paths, sample_fraction=None):\n",
        "    sample = []\n",
        "\n",
        "    for filename in samples_paths:\n",
        "        print(f\"> Loading {filename}\")\n",
        "        part = torch.load(filename)\n",
        "\n",
        "        if type(part) == list: \n",
        "            part = torch.cat(part)\n",
        "        if sample_fraction:\n",
        "            part = part[torch.randint(0, high=part.size(0), size=(int(part.size(0) * sample_fraction),))]\n",
        "\n",
        "        sample.append(part)\n",
        "\n",
        "    sample = torch.cat(sample).float().numpy()\n",
        "    return sample\n",
        "\n",
        "def get_parts(directory):\n",
        "    extension = '.pt'\n",
        "\n",
        "    parts = sorted([int(filename[: -1 * len(extension)]) for filename in os.listdir(directory)\n",
        "                    if filename.endswith(extension)])\n",
        "\n",
        "    assert list(range(len(parts))) == parts, parts\n",
        "\n",
        "    # Integer-sortedness matters.\n",
        "    parts_paths = [os.path.join(directory, '{}{}'.format(filename, extension)) for filename in parts]\n",
        "    samples_paths = [os.path.join(directory, '{}.sample'.format(filename)) for filename in parts]\n",
        "\n",
        "    return parts, parts_paths, samples_paths\n",
        "\n",
        "def prepare_faiss_index(slice_samples_paths, partitions, sample_fraction=None):\n",
        "    training_sample = load_sample(slice_samples_paths, sample_fraction=sample_fraction)\n",
        "\n",
        "    dim = training_sample.shape[-1]\n",
        "    index = FaissIndex(dim, partitions)\n",
        "    print(\"> Training with the vectors...\")\n",
        "    index.train(training_sample)\n",
        "    print(\"  Done training!\\n\")\n",
        "\n",
        "    return index\n",
        "\n",
        "# ===============\n",
        "# âœ¨ index_faiss\n",
        "# ===============\n",
        "def index_faiss(index_path, partitions, sample):\n",
        "\n",
        "    parts, parts_paths, samples_paths = get_parts(index_path)\n",
        "    \n",
        "    if sample is not None:\n",
        "        print(f\"Training with {round(sample * 100.0, 1)}% of all embeddings provided.\\n\")\n",
        "        samples_paths = parts_paths\n",
        "\n",
        "    output_path = os.path.join(index_path, f'ivfpq.{str(partitions)}.faiss')\n",
        "\n",
        "    index = prepare_faiss_index(samples_paths, partitions, sample)\n",
        "\n",
        "    for filename in parts_paths:\n",
        "        part = torch.load(filename)\n",
        "        \n",
        "        if type(part) == list: \n",
        "            part = torch.cat(part)\n",
        "        \n",
        "        part = part.float().numpy()\n",
        "        index.add(part)\n",
        "\n",
        "    index.save(output_path)\n",
        "\n",
        "    print(f\"\\nDone! All complete!\")    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogeTkQEcoDTo",
        "outputId": "c9064437-9c32-45dc-fc22-39cb42a91bb9"
      },
      "source": [
        "# - - - - - \n",
        "# âœ¨ Build faiss indexes for train set\n",
        "index_faiss(\n",
        "    index_path=path_base+'index/train_index',\n",
        "    partitions=100, \n",
        "    sample=0.30,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with 30.0% of all embeddings provided.\n",
            "\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/train_index/0.pt\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/train_index/1.pt\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/train_index/2.pt\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/train_index/3.pt\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/train_index/4.pt\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/train_index/5.pt\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/train_index/6.pt\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/train_index/7.pt\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/train_index/8.pt\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/train_index/9.pt\n",
            "\n",
            "Preparing resources for 1 GPUs.\n",
            "> Training with the vectors...\n",
            "  Done training!\n",
            "\n",
            "\tAdd data with shape (6096, 128) (offset = 0)\n",
            "\n",
            "\tAdd data with shape (6184, 128) (offset = 6096)\n",
            "\n",
            "\tAdd data with shape (6271, 128) (offset = 12280)\n",
            "\n",
            "\tAdd data with shape (5856, 128) (offset = 18551)\n",
            "\n",
            "\tAdd data with shape (6667, 128) (offset = 24407)\n",
            "\n",
            "\tAdd data with shape (6349, 128) (offset = 31074)\n",
            "\n",
            "\tAdd data with shape (6581, 128) (offset = 37423)\n",
            "\n",
            "\tAdd data with shape (5917, 128) (offset = 44004)\n",
            "\n",
            "\tAdd data with shape (5845, 128) (offset = 49921)\n",
            "\n",
            "\tAdd data with shape (3507, 128) (offset = 55766)\n",
            "\n",
            "\n",
            "Writing index to /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/train_index/ivfpq.100.faiss\n",
            "\n",
            "Done! All complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEgM9XNmoESZ",
        "outputId": "c5ee2df9-b9a7-4b95-e756-44262849a8f6"
      },
      "source": [
        "# âœ¨ Build faiss indexes for valid set\n",
        "index_faiss(\n",
        "    index_path=path_base+'index/valid_index',\n",
        "    partitions=50, \n",
        "    sample=0.30,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with 30.0% of all embeddings provided.\n",
            "\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/valid_index/0.pt\n",
            "> Loading /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/valid_index/1.pt\n",
            "\n",
            "Preparing resources for 1 GPUs.\n",
            "> Training with the vectors...\n",
            "  Done training!\n",
            "\n",
            "\tAdd data with shape (6166, 128) (offset = 0)\n",
            "\n",
            "\tAdd data with shape (384, 128) (offset = 6166)\n",
            "\n",
            "\n",
            "Writing index to /content/drive/MyDrive/ColBERT/ColBERT - FAQ Receita Federal//index/valid_index/ivfpq.50.faiss\n",
            "\n",
            "Done! All complete!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
